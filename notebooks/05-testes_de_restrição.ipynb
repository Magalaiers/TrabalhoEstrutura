{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Modelo pré-treinado carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Célula 1: Setup Completo para o Notebook de Testes\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib # Importa a biblioteca para carregar o modelo\n",
    "\n",
    "# --- 1. Configuração do Path ---\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Adicionado ao path: {project_root}\")\n",
    "\n",
    "# --- 2. Imports das suas Estruturas ---\n",
    "from src.estrutura_de_dados.arvore_avl import AVLTree\n",
    "# ... importe outras se precisar ...\n",
    "\n",
    "# --- 3. Preparação dos Dados (Precisamos de X_test_scaled e y_test) ---\n",
    "df = pd.read_csv(\"../dataset/heart_attack_prediction_dataset.csv\")\n",
    "if 'Patient ID' in df.columns: df = df.drop('Patient ID', axis=1)\n",
    "\n",
    "nome_coluna_alvo = 'Heart Attack Risk'\n",
    "X = df.drop(nome_coluna_alvo, axis=1)\n",
    "y = df[nome_coluna_alvo]\n",
    "\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# --- 4. CARREGAR O MODELO TREINADO ---\n",
    "try:\n",
    "    modelo_final = joblib.load('../models/modelo_arvore_final.joblib')\n",
    "    print(\"\\n✅ Modelo pré-treinado carregado com sucesso!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n❌ ERRO: Arquivo do modelo não encontrado. Certifique-se de executar o Passo 1 no outro notebook para salvá-lo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ambiente configurado e dados carregados!\n"
     ]
    }
   ],
   "source": [
    "# Célula 1: Configuração do Ambiente e Imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Adiciona a raiz do projeto ao Python Path para que possamos importar de 'src'\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Adicionado ao path: {project_root}\")\n",
    "\n",
    "# Agora você pode importar suas estruturas e carregar os dados\n",
    "# ATENÇÃO: Usei os nomes das suas pastas que apareceram no erro. Verifique se estão corretos.\n",
    "from src.estrutura_de_dados.arvore_avl import AVLTree\n",
    "from src.estrutura_de_dados.lista_encadeada import LinkedList\n",
    "from src.estrutura_de_dados.tabela_hash import HashTable\n",
    "# ... importe as outras estruturas que precisar\n",
    "\n",
    "# Carrega o dataframe\n",
    "df = pd.read_csv(\"../dataset/heart_attack_prediction_dataset.csv\") \n",
    "\n",
    "print(\"\\nAmbiente configurado e dados carregados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uso de memória original: 4.64 MB\n",
      "Uso de memória compactado: 3.64 MB\n",
      "Redução de memória: 21.45%\n",
      "\n",
      "Tipos de dados antes:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8763 entries, 0 to 8762\n",
      "Data columns (total 26 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Patient ID                       8763 non-null   object \n",
      " 1   Age                              8763 non-null   int64  \n",
      " 2   Sex                              8763 non-null   object \n",
      " 3   Cholesterol                      8763 non-null   int64  \n",
      " 4   Blood Pressure                   8763 non-null   object \n",
      " 5   Heart Rate                       8763 non-null   int64  \n",
      " 6   Diabetes                         8763 non-null   int64  \n",
      " 7   Family History                   8763 non-null   int64  \n",
      " 8   Smoking                          8763 non-null   int64  \n",
      " 9   Obesity                          8763 non-null   int64  \n",
      " 10  Alcohol Consumption              8763 non-null   int64  \n",
      " 11  Exercise Hours Per Week          8763 non-null   float64\n",
      " 12  Diet                             8763 non-null   object \n",
      " 13  Previous Heart Problems          8763 non-null   int64  \n",
      " 14  Medication Use                   8763 non-null   int64  \n",
      " 15  Stress Level                     8763 non-null   int64  \n",
      " 16  Sedentary Hours Per Day          8763 non-null   float64\n",
      " 17  Income                           8763 non-null   int64  \n",
      " 18  BMI                              8763 non-null   float64\n",
      " 19  Triglycerides                    8763 non-null   int64  \n",
      " 20  Physical Activity Days Per Week  8763 non-null   int64  \n",
      " 21  Sleep Hours Per Day              8763 non-null   int64  \n",
      " 22  Country                          8763 non-null   object \n",
      " 23  Continent                        8763 non-null   object \n",
      " 24  Hemisphere                       8763 non-null   object \n",
      " 25  Heart Attack Risk                8763 non-null   int64  \n",
      "dtypes: float64(3), int64(16), object(7)\n",
      "memory usage: 1.7+ MB\n",
      "None\n",
      "\n",
      "Tipos de dados depois:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8763 entries, 0 to 8762\n",
      "Data columns (total 26 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Patient ID                       8763 non-null   object \n",
      " 1   Age                              8763 non-null   int8   \n",
      " 2   Sex                              8763 non-null   object \n",
      " 3   Cholesterol                      8763 non-null   int16  \n",
      " 4   Blood Pressure                   8763 non-null   object \n",
      " 5   Heart Rate                       8763 non-null   int8   \n",
      " 6   Diabetes                         8763 non-null   int8   \n",
      " 7   Family History                   8763 non-null   int8   \n",
      " 8   Smoking                          8763 non-null   int8   \n",
      " 9   Obesity                          8763 non-null   int8   \n",
      " 10  Alcohol Consumption              8763 non-null   int8   \n",
      " 11  Exercise Hours Per Week          8763 non-null   float32\n",
      " 12  Diet                             8763 non-null   object \n",
      " 13  Previous Heart Problems          8763 non-null   int8   \n",
      " 14  Medication Use                   8763 non-null   int8   \n",
      " 15  Stress Level                     8763 non-null   int8   \n",
      " 16  Sedentary Hours Per Day          8763 non-null   float32\n",
      " 17  Income                           8763 non-null   float32\n",
      " 18  BMI                              8763 non-null   float32\n",
      " 19  Triglycerides                    8763 non-null   int16  \n",
      " 20  Physical Activity Days Per Week  8763 non-null   int8   \n",
      " 21  Sleep Hours Per Day              8763 non-null   int8   \n",
      " 22  Country                          8763 non-null   object \n",
      " 23  Continent                        8763 non-null   object \n",
      " 24  Hemisphere                       8763 non-null   object \n",
      " 25  Heart Attack Risk                8763 non-null   int8   \n",
      "dtypes: float32(4), int16(2), int8(13), object(7)\n",
      "memory usage: 761.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Célula 1: Teste de Restrição de Memória (R3)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregue o dataset original\n",
    "caminho_do_arquivo = \"../dataset/heart_attack_prediction_dataset.csv\" \n",
    "df_original = pd.read_csv(caminho_do_arquivo)\n",
    "memoria_antes = df_original.memory_usage(deep=True).sum()\n",
    "\n",
    "print(f\"Uso de memória original: {memoria_antes / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Cria uma cópia para compactar\n",
    "df_compactado = df_original.copy()\n",
    "\n",
    "# Percorre as colunas numéricas e tenta diminuir o tipo de dado\n",
    "for col in df_compactado.select_dtypes(include=np.number).columns:\n",
    "    # Downcast para o menor tipo de inteiro ou float possível\n",
    "    df_compactado[col] = pd.to_numeric(df_compactado[col], downcast='integer')\n",
    "    df_compactado[col] = pd.to_numeric(df_compactado[col], downcast='float')\n",
    "\n",
    "memoria_depois = df_compactado.memory_usage(deep=True).sum()\n",
    "reducao = (1 - memoria_depois / memoria_antes) * 100\n",
    "\n",
    "print(f\"Uso de memória compactado: {memoria_depois / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Redução de memória: {reducao:.2f}%\")\n",
    "\n",
    "print(\"\\nTipos de dados antes:\")\n",
    "print(df_original.info())\n",
    "print(\"\\nTipos de dados depois:\")\n",
    "print(df_compactado.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Teste de Processamento (R9) - Versão Robusta com Múltiplas Rodadas ---\n",
      "Executando 5 rodadas de cada teste...\n",
      "Rodada 1/5 concluída...\n",
      "Rodada 2/5 concluída...\n",
      "Rodada 3/5 concluída...\n",
      "Rodada 4/5 concluída...\n",
      "Rodada 5/5 concluída...\n",
      "\n",
      "--- Resultados Médios ---\n",
      "Tempo médio de inserção normal: 0.0211 segundos\n",
      "Tempo médio com carga extra:   0.0247 segundos\n",
      "\n",
      "A carga extra aumentou o tempo médio de execução em: 17.04%\n"
     ]
    }
   ],
   "source": [
    "# Célula para Teste de Restrição de Processamento (R9) - VERSÃO ROBUSTA\n",
    "\n",
    "print(\"\\n--- Iniciando Teste de Processamento (R9) - Versão Robusta com Múltiplas Rodadas ---\")\n",
    "NUM_ITENS = 3000\n",
    "N_RODADAS = 5 # Vamos executar cada cenário 5 vezes e tirar a média\n",
    "dados_teste = df['Age'].head(NUM_ITENS)\n",
    "\n",
    "tempos_normais = []\n",
    "tempos_carga = []\n",
    "\n",
    "print(f\"Executando {N_RODADAS} rodadas de cada teste...\")\n",
    "\n",
    "for i in range(N_RODADAS):\n",
    "    # --- Teste Normal ---\n",
    "    avl_normal = AVLTree()\n",
    "    start_normal = time.perf_counter()\n",
    "    for item in dados_teste:\n",
    "        avl_normal.insert(item)\n",
    "    tempos_normais.append(time.perf_counter() - start_normal)\n",
    "\n",
    "    # --- Teste com Carga Extra ---\n",
    "    avl_carga = AVLTree()\n",
    "    start_carga = time.perf_counter()\n",
    "    for item in dados_teste:\n",
    "        avl_carga.insert(item)\n",
    "        [(_**2) for _ in range(10)] # Carga extra\n",
    "    tempos_carga.append(time.perf_counter() - start_carga)\n",
    "    \n",
    "    print(f\"Rodada {i+1}/{N_RODADAS} concluída...\")\n",
    "\n",
    "# Calcula a média dos resultados, ignorando a primeira rodada (que serviu de aquecimento)\n",
    "avg_normal = np.mean(tempos_normais[1:])\n",
    "avg_carga = np.mean(tempos_carga[1:])\n",
    "\n",
    "print(\"\\n--- Resultados Médios ---\")\n",
    "print(f\"Tempo médio de inserção normal: {avg_normal:.4f} segundos\")\n",
    "print(f\"Tempo médio com carga extra:   {avg_carga:.4f} segundos\")\n",
    "\n",
    "if avg_normal > 0 and avg_carga > avg_normal:\n",
    "    aumento_percentual = ((avg_carga - avg_normal) / avg_normal) * 100\n",
    "    print(f\"\\nA carga extra aumentou o tempo médio de execução em: {aumento_percentual:.2f}%\")\n",
    "else:\n",
    "    print(\"\\nResultado do teste inconsistente. A carga extra não demonstrou um aumento de tempo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Teste de Latência (R11) Comparativo ---\n",
      "\n",
      "Testando: Lista Encadeada\n",
      "  Tempo para 2000 buscas (sem latência): 0.0083 segundos\n",
      "  Tempo com latência: 1.2049 segundos\n",
      "\n",
      "Testando: Árvore AVL\n",
      "  Tempo para 2000 buscas (sem latência): 0.0012 segundos\n",
      "  Tempo com latência: 1.2082 segundos\n",
      "\n",
      "Testando: Tabela Hash\n",
      "  Tempo para 2000 buscas (sem latência): 0.0013 segundos\n",
      "  Tempo com latência: 1.3395 segundos\n",
      "\n",
      "--- Resultados do Teste de Latência ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_401ba\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_401ba_level0_col0\" class=\"col_heading level0 col0\" >Tempo Sem Latência (s)</th>\n",
       "      <th id=\"T_401ba_level0_col1\" class=\"col_heading level0 col1\" >Tempo Com Latência (s)</th>\n",
       "      <th id=\"T_401ba_level0_col2\" class=\"col_heading level0 col2\" >Sobrecarga Total (s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Estrutura</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_401ba_level0_row0\" class=\"row_heading level0 row0\" >Lista Encadeada</th>\n",
       "      <td id=\"T_401ba_row0_col0\" class=\"data row0 col0\" >0.0083</td>\n",
       "      <td id=\"T_401ba_row0_col1\" class=\"data row0 col1\" >1.2049</td>\n",
       "      <td id=\"T_401ba_row0_col2\" class=\"data row0 col2\" >1.1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_401ba_level0_row1\" class=\"row_heading level0 row1\" >Árvore AVL</th>\n",
       "      <td id=\"T_401ba_row1_col0\" class=\"data row1 col0\" >0.0012</td>\n",
       "      <td id=\"T_401ba_row1_col1\" class=\"data row1 col1\" >1.2082</td>\n",
       "      <td id=\"T_401ba_row1_col2\" class=\"data row1 col2\" >1.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_401ba_level0_row2\" class=\"row_heading level0 row2\" >Tabela Hash</th>\n",
       "      <td id=\"T_401ba_row2_col0\" class=\"data row2 col0\" >0.0013</td>\n",
       "      <td id=\"T_401ba_row2_col1\" class=\"data row2 col1\" >1.3395</td>\n",
       "      <td id=\"T_401ba_row2_col2\" class=\"data row2 col2\" >1.3381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16941264c20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Célula para Teste de Restrição de Latência (R11) - Comparativo\n",
    "\n",
    "print(\"\\n--- Iniciando Teste de Latência (R11) Comparativo ---\")\n",
    "NUM_BUSCAS = 2000\n",
    "LATENCIA_SIMULADA = 0.0001 # 0.1 ms\n",
    "\n",
    "# Prepara os dados uma única vez\n",
    "dados_numericos = df['Age'].head(NUM_BUSCAS).tolist()\n",
    "dados_chave_valor = df['Age'].head(NUM_BUSCAS).to_dict()\n",
    "\n",
    "# Popula as estruturas que vamos testar\n",
    "ll = LinkedList(); [ll.insert(item) for item in dados_numericos]\n",
    "avl = AVLTree(); [avl.insert(item) for item in dados_numericos]\n",
    "ht = HashTable(size=NUM_BUSCAS * 2); [ht.insert(k, v) for k, v in dados_chave_valor.items()]\n",
    "\n",
    "estruturas_para_teste = {\n",
    "    \"Lista Encadeada\": ll,\n",
    "    \"Árvore AVL\": avl,\n",
    "    \"Tabela Hash\": ht\n",
    "}\n",
    "\n",
    "resultados_lat = []\n",
    "\n",
    "for nome, instancia in estruturas_para_teste.items():\n",
    "    print(f\"\\nTestando: {nome}\")\n",
    "    \n",
    "    # Teste Normal (sem latência)\n",
    "    start_normal = time.perf_counter()\n",
    "    if nome == \"Tabela Hash\": [instancia.search(k) for k in dados_chave_valor.keys()]\n",
    "    else: [instancia.search(item) for item in dados_numericos]\n",
    "    tempo_normal = time.perf_counter() - start_normal\n",
    "    print(f\"  Tempo para {NUM_BUSCAS} buscas (sem latência): {tempo_normal:.4f} segundos\")\n",
    "\n",
    "    # Teste com Latência\n",
    "    start_latencia = time.perf_counter()\n",
    "    if nome == \"Tabela Hash\":\n",
    "        for k in dados_chave_valor.keys(): instancia.search(k); time.sleep(LATENCIA_SIMULADA)\n",
    "    else:\n",
    "        for item in dados_numericos: instancia.search(item); time.sleep(LATENCIA_SIMULADA)\n",
    "    tempo_latencia = time.perf_counter() - start_latencia\n",
    "    print(f\"  Tempo com latência: {tempo_latencia:.4f} segundos\")\n",
    "    \n",
    "    resultados_lat.append({\n",
    "        \"Estrutura\": nome,\n",
    "        \"Tempo Sem Latência (s)\": tempo_normal,\n",
    "        \"Tempo Com Latência (s)\": tempo_latencia,\n",
    "        \"Sobrecarga Total (s)\": tempo_latencia - tempo_normal\n",
    "    })\n",
    "    \n",
    "# Exibe a tabela de resultados\n",
    "df_lat = pd.DataFrame(resultados_lat).set_index('Estrutura')\n",
    "print(\"\\n--- Resultados do Teste de Latência ---\")\n",
    "display(df_lat.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Teste de Dados (R18) ---\n",
      "✅ Modelo, scaler e dataset carregados.\n",
      "Preparando dados para o formato esperado pelo modelo...\n",
      "✅ Dados de teste preparados e sincronizados com o modelo.\n",
      "\n",
      "Acurácia do modelo em dados limpos: 64.18%\n",
      "Acurácia do modelo em dados corrompidos: 64.18%\n",
      "A performance do modelo degradou em: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yutam\\OneDrive\\Documentos\\GitHub\\TrabalhoEstrutura\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\yutam\\OneDrive\\Documentos\\GitHub\\TrabalhoEstrutura\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Célula para Teste de Restrição de Dados (R18) - VERSÃO CORRIGIDA\n",
    "\n",
    "# --- 1. Imports e Carregamento de Recursos ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"\\n--- Iniciando Teste de Dados (R18) ---\")\n",
    "\n",
    "try:\n",
    "    # Carrega o modelo e o scaler salvos\n",
    "    modelo_final = joblib.load(os.path.join(\"..\", \"models\", \"modelo_arvore_final.joblib\"))\n",
    "    scaler = joblib.load(os.path.join(\"..\", \"models\", \"scaler.joblib\"))\n",
    "    \n",
    "    # Carrega o dataset cru\n",
    "    df = pd.read_csv(os.path.join(\"..\", \"dataset\", \"heart_attack_prediction_dataset.csv\"))\n",
    "    print(\"✅ Modelo, scaler e dataset carregados.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ ERRO: Arquivo não encontrado: {e.filename}\")\n",
    "    assert False, \"Certifique-se de que os modelos foram salvos e o dataset existe.\"\n",
    "\n",
    "\n",
    "# --- 2. Pipeline de Preparação de Dados (IDÊNTICO AO DO main.py) ---\n",
    "print(\"Preparando dados para o formato esperado pelo modelo...\")\n",
    "\n",
    "# Processa colunas complexas\n",
    "if 'Blood Pressure' in df.columns:\n",
    "    split_bp = df['Blood Pressure'].str.split('/', expand=True)\n",
    "    df['Pressao_Sistolica'] = pd.to_numeric(split_bp[0], errors='coerce')\n",
    "    df['Pressao_Diastolica'] = pd.to_numeric(split_bp[1], errors='coerce')\n",
    "    df = df.drop(columns=['Blood Pressure'])\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Seleciona exatamente as mesmas features usadas no treinamento\n",
    "colunas_para_modelo = [\n",
    "    'Age', 'Sex', 'Cholesterol', 'Heart Rate', 'Diabetes', 'Family History', \n",
    "    'Smoking', 'Obesity', 'Alcohol Consumption', 'Exercise Hours Per Week', 'Diet', \n",
    "    'Previous Heart Problems', 'Medication Use', 'Stress Level', 'Sedentary Hours Per Day', \n",
    "    'Income', 'BMI', 'Triglycerides', 'Physical Activity Days Per Week', 'Sleep Hours Per Day', \n",
    "    'Pressao_Sistolica', 'Pressao_Diastolica'\n",
    "]\n",
    "colunas_para_modelo = [col for col in colunas_para_modelo if col in df.columns]\n",
    "\n",
    "X = df[colunas_para_modelo]\n",
    "y = df['Heart Attack Risk']\n",
    "\n",
    "# One-Hot Encoding apenas nas features selecionadas\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Divisão em treino/teste (só para simular e obter um X_test)\n",
    "_, X_test, _, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Garante que as colunas do X_test sejam EXATAMENTE as mesmas que o scaler espera\n",
    "expected_features = scaler.feature_names_in_\n",
    "X_test_alinhado = X_test.reindex(columns=expected_features, fill_value=0)\n",
    "\n",
    "# Aplica o scaling\n",
    "X_test_scaled = scaler.transform(X_test_alinhado)\n",
    "print(\"✅ Dados de teste preparados e sincronizados com o modelo.\")\n",
    "\n",
    "\n",
    "# --- 3. Execução do Teste ---\n",
    "\n",
    "# Acurácia original\n",
    "acuracia_original = modelo_final.score(X_test_scaled, y_test)\n",
    "print(f\"\\nAcurácia do modelo em dados limpos: {acuracia_original:.2%}\")\n",
    "\n",
    "# Corrompendo 15% dos dados de teste\n",
    "X_test_corrompido = X_test_scaled.copy()\n",
    "# Encontra o índice da coluna 'Age' no array numpy para corromper\n",
    "coluna_age_index = list(X_test_alinhado.columns).index('Age')\n",
    "indices_corrompidos = np.random.choice(X_test_corrompido.shape[0], size=int(X_test_corrompido.shape[0] * 0.15), replace=False)\n",
    "X_test_corrompido[indices_corrompidos, coluna_age_index] = 99 # Injeta valor anômalo\n",
    "\n",
    "# Acurácia com dados corrompidos\n",
    "acuracia_corrompida = modelo_final.score(X_test_corrompido, y_test)\n",
    "print(f\"Acurácia do modelo em dados corrompidos: {acuracia_corrompida:.2%}\")\n",
    "\n",
    "degradacao = abs(acuracia_original - acuracia_corrompida) / acuracia_original * 100\n",
    "print(f\"A performance do modelo degradou em: {degradacao:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Teste de Restrição Algorítmica (R23) ---\n",
      "Tarefa: Medir a sobrecarga de uma operação de 'encriptação' em inserções.\n",
      "Número de inserções a serem testadas: 5000\n",
      "\n",
      "--- Testando Inserção Normal ---\n",
      "Tempo de inserção normal: 0.0061 segundos\n",
      "\n",
      "--- Testando Inserção com 'Encriptação' ---\n",
      "Tempo de inserção com 'encriptação': 0.0143 segundos\n",
      "\n",
      "--- Conclusão ---\n",
      "A sobrecarga da 'encriptação' foi de 0.0082 segundos.\n",
      "Isso representa um aumento de 133.13% no tempo total de inserção.\n"
     ]
    }
   ],
   "source": [
    "# Célula para Teste de Restrição Algorítmica (R23) - Carga de Encriptação\n",
    "\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "def encrypt_data(data):\n",
    "    \"\"\"\n",
    "    Simula uma operação de encriptação usando um hash SHA-256.\n",
    "    Retorna a representação hexadecimal do hash.\n",
    "    \"\"\"\n",
    "    # Converte o dado para string, depois para bytes, para poder usar o hash\n",
    "    return hashlib.sha256(str(data).encode()).hexdigest()\n",
    "\n",
    "print(\"\\n--- Iniciando Teste de Restrição Algorítmica (R23) ---\")\n",
    "print(\"Tarefa: Medir a sobrecarga de uma operação de 'encriptação' em inserções.\")\n",
    "\n",
    "NUM_ITENS_ENCRIPTACAO = 5000\n",
    "dados_para_inserir = df['Age'].head(NUM_ITENS_ENCRIPTACAO).to_dict()\n",
    "print(f\"Número de inserções a serem testadas: {NUM_ITENS_ENCRIPTACAO}\\n\")\n",
    "\n",
    "\n",
    "# --- Método 1: Inserção Normal (Sem Encriptação) ---\n",
    "print(\"--- Testando Inserção Normal ---\")\n",
    "ht_normal = HashTable(size=NUM_ITENS_ENCRIPTACAO * 2)\n",
    "\n",
    "start_normal = time.perf_counter()\n",
    "for key, value in dados_para_inserir.items():\n",
    "    ht_normal.insert(key, value)\n",
    "tempo_normal = time.perf_counter() - start_normal\n",
    "print(f\"Tempo de inserção normal: {tempo_normal:.4f} segundos\")\n",
    "\n",
    "\n",
    "# --- Método 2: Inserção com Carga de \"Encriptação\" ---\n",
    "print(\"\\n--- Testando Inserção com 'Encriptação' ---\")\n",
    "ht_encriptada = HashTable(size=NUM_ITENS_ENCRIPTACAO * 2)\n",
    "\n",
    "start_encriptada = time.perf_counter()\n",
    "for key, value in dados_para_inserir.items():\n",
    "    # Passo extra: \"encripta\" o valor antes de inserir\n",
    "    valor_encriptado = encrypt_data(value)\n",
    "    ht_encriptada.insert(key, valor_encriptado)\n",
    "tempo_encriptada = time.perf_counter() - start_encriptada\n",
    "print(f\"Tempo de inserção com 'encriptação': {tempo_encriptada:.4f} segundos\")\n",
    "\n",
    "\n",
    "# --- Conclusão do Teste ---\n",
    "print(\"\\n--- Conclusão ---\")\n",
    "sobrecarga = tempo_encriptada - tempo_normal\n",
    "aumento_percentual = (sobrecarga / tempo_normal) * 100\n",
    "\n",
    "print(f\"A sobrecarga da 'encriptação' foi de {sobrecarga:.4f} segundos.\")\n",
    "print(f\"Isso representa um aumento de {aumento_percentual:.2f}% no tempo total de inserção.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
